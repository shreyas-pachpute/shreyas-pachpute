<div align="center">
  <img src="https://komarev.com/ghpvc/?username=shreyas-pachpute&color=blue&style=flat-square" alt="Profile Views" />
  
  <br />
  <br />

  <h1>Hi, I'm Shreyas Pachpute</h1>
  <h3>AI Architect & GenAI Systems Engineer</h3>
  
  <p>
    <b>Building production RAG, multi-agent workflows, and cost-optimized LLM inference on AWS.</b><br>
    Specialized in moving GenAI from prototypes to scalable, observable systems.
  </p>

  <p>
    <b>150+</b> tok/sec on vLLM &nbsp;|&nbsp; 
    <b>$15K+</b> infra savings &nbsp;|&nbsp; 
    <b><300ms</b> RAG p95 latency
  </p>

  <p>
    <a href="https://linkedin.com/in/shreyas-pachpute-b5882a204">
      <img src="https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn">
    </a>
    <a href="https://shreyas-pachpute.github.io">
      <img src="https://img.shields.io/badge/Portfolio-View_Live-black?style=for-the-badge&logo=vercel&logoColor=white" alt="Portfolio">
    </a>
    <a href="mailto:shreyaspachpute1107@gmail.com">
      <img src="https://img.shields.io/badge/Email-Contact_Me-C71610?style=for-the-badge&logo=gmail&logoColor=white" alt="Email">
    </a>
  </p>
</div>

<br />

## ğŸ¯ What I Build
I design enterprise-grade GenAI systems. My focus is not just on model accuracy, but on **inference latency, infrastructure cost, and system reliability**.

**Recent Engineering Impact:**
- ğŸš€ **Multi-agent Support System**: 70% ticket deflection, 85% auto-resolution rate.
- ğŸ’° **vLLM Optimization**: $15K annual savings vs. commercial APIs via g5.xlarge instances.
- âš¡ **Enterprise RAG**: <300ms p95 latency at 50K queries/day, 94% classification accuracy.
- â˜ï¸ **AWS Infra**: Containerized deployments (ECS/Lambda) with 99.8% uptime.

---

## ğŸ—ï¸ Architecture Showcase

These repositories demonstrate production standards: **Architecture Diagrams**, **Metrics**, and **Infrastructure-as-Code**.

### ğŸ”¹ [Production RAG Engine (HSN Classifier)](https://github.com/shreyas-pachpute/production-rag-hsn-classifier)
> Enterprise-grade retrieval system with hybrid search and reranking.

- **Architecture**: Hybrid Search (BM25 + Semantic) â†’ Cross-Encoder Reranking â†’ Redis Cache.
- **Metrics**: **94% accuracy**, 80% manual time reduction, sub-300ms latency.
- **Stack**: ChromaDB, Sentence-Transformers, FastAPI, AWS Lambda.

### ğŸ”¹ [Multi-Agent Support System](https://github.com/shreyas-pachpute/multi-agent-support-system)
> AutoGen-based workflow orchestration with circuit breakers.

- **Architecture**: Orchestrator â†’ Diagnostic Agent â†’ Policy Agent â†’ Escalation Handler.
- **Metrics**: **70% ticket deflection**, 85% auto-resolution.
- **Stack**: AutoGen, LangChain, Redis Queues, Docker, Prometheus.

### ğŸ”¹ [vLLM Inference Optimizer](https://github.com/shreyas-pachpute/vllm-inference-optimizer)
> Cost-optimized Llama 3 deployment with dynamic batching.

- **Architecture**: AWS g5.xlarge + vLLM (PagedAttention) + GPTQ Quantization.
- **Metrics**: **150 tok/sec throughput**, $15K annual savings, 87% GPU utilization.
- **Stack**: vLLM, PyTorch, CUDA, Terraform, Grafana.

---

## ğŸ’¼ Professional Experience

### Commercient LLC Â· AI Architect & Engineer (Jan 2024 â€“ Present)

**Dynamic RAG Platform & HSN Classification**
- Architected a multi-tenant RAG system ingesting 10K+ docs/day with sub-300ms response latency.
- Built a classifier achieving **94% accuracy** on product codes, reducing manual work by **80%**.
- **Tech**: Pinecone, LangChain, FastAPI, AWS Lambda.

**LLM Inference Infrastructure**
- Engineered self-hosted inference for Llama 3 on AWS g5.xlarge using vLLM.
- Achieved **150 tok/sec throughput** and a **40% cost reduction** vs OpenAI APIs.
- **Tech**: vLLM, Docker, CUDA, AWS EC2, Prometheus.

**Production AI Agents**
- **Sales Agent**: drove **40% increase** in qualified leads via HubSpot integration.
- **Support Agent**: achieved **70% ticket deflection** rate via Zendesk sync.
- **Tech**: AutoGen, LangChain, Redis, PostgreSQL.

---

## ğŸ”§ Technical Stack

| Area | Technologies |
|:---:|:---|
| **GenAI Systems** | LangChain, LlamaIndex, AutoGen, vLLM, HuggingFace, OpenAI API |
| **Vector Database** | Pinecone, ChromaDB, Qdrant, Milvus |
| **Backend & API** | Python, FastAPI, Microservices, RabbitMQ, C# (.NET) |
| **Cloud & Infra** | AWS (SageMaker, Lambda, ECS, EC2), Docker, Kubernetes, Terraform |
| **MLOps** | MLflow, DVC, Prometheus, Grafana, GitHub Actions |

---

## ğŸš§ Currently Building

- ğŸ“Š **LLM A/B Testing Framework**: Statistical significance testing for prompts using MLflow.
- ğŸ”„ **Fine-tuning MLOps Pipeline**: Automated LoRA training on SageMaker with DVC.
- ğŸ“ˆ **Cost-Optimized Embedding Pipeline**: Batch processing 1M docs at 10x lower cost.

---

## ğŸ’¼ Open to Opportunities

ğŸ” **Seeking:** Senior AI Architect / Principal GenAI Engineer  
ğŸ¯ **Focus:** RAG systems, LLM infrastructure, Multi-agent workflows, AWS  
ğŸŒ **Location:** Remote (US/Europe preferred)

[**View My Full Portfolio Website**](https://shreyas-pachpute.github.io) | [**Download Resume**](https://shreyas-pachpute.github.io/documents/Shreyas_Pachpute_Resume.pdf)

<!-- Footer -->
<div align="center">
  <br>
  <img src="https://img.shields.io/github/followers/shreyas-pachpute?style=social" alt="GitHub Followers" />
  <img src="https://img.shields.io/github/stars/shreyas-pachpute?style=social" alt="GitHub Stars" />
</div>
